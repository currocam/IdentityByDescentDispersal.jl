<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Inference and model evaluation · IdentityByDescentDispersal.jl</title><meta name="title" content="Inference and model evaluation · IdentityByDescentDispersal.jl"/><meta property="og:title" content="Inference and model evaluation · IdentityByDescentDispersal.jl"/><meta property="twitter:title" content="Inference and model evaluation · IdentityByDescentDispersal.jl"/><meta name="description" content="Documentation for IdentityByDescentDispersal.jl."/><meta property="og:description" content="Documentation for IdentityByDescentDispersal.jl."/><meta property="twitter:description" content="Documentation for IdentityByDescentDispersal.jl."/><meta property="og:url" content="https://currocam.github.io/IdentityByDescentDispersal.jl/inference/"/><meta property="twitter:url" content="https://currocam.github.io/IdentityByDescentDispersal.jl/inference/"/><link rel="canonical" href="https://currocam.github.io/IdentityByDescentDispersal.jl/inference/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">IdentityByDescentDispersal.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../overview/">Theory overview</a></li><li><a class="tocitem" href="../tutorial/">Basic usage</a></li><li class="is-active"><a class="tocitem" href>Inference and model evaluation</a><ul class="internal"><li><a class="tocitem" href="#Simulating-synthetic-datasets"><span>Simulating synthetic datasets</span></a></li><li><a class="tocitem" href="#Processing-pipeline"><span>Processing pipeline</span></a></li><li><a class="tocitem" href="#Model-inference"><span>Model inference</span></a></li><li><a class="tocitem" href="#Model-diagnosis"><span>Model diagnosis</span></a></li><li><a class="tocitem" href="#Visualizing-the-posterior"><span>Visualizing the posterior</span></a></li><li><a class="tocitem" href="#Interpreting-the-output"><span>Interpreting the output</span></a></li></ul></li><li><span class="tocitem">Developer docs</span><ul><li><a class="tocitem" href="../95-reference/">API reference</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Inference and model evaluation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Inference and model evaluation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/currocam/IdentityByDescentDispersal.jl/blob/main/docs/src/inference.jl#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Inference-and-model-evaluation"><a class="docs-heading-anchor" href="#Inference-and-model-evaluation">Inference and model evaluation</a><a id="Inference-and-model-evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-and-model-evaluation" title="Permalink"></a></h1><p>In this section, we go through the process of estimating the parameters of the model and evaluating the fitted model.</p><h2 id="Simulating-synthetic-datasets"><a class="docs-heading-anchor" href="#Simulating-synthetic-datasets">Simulating synthetic datasets</a><a id="Simulating-synthetic-datasets-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-synthetic-datasets" title="Permalink"></a></h2><p>The method proposed by [<a href="../references/#ringbauer_inferring_2017">1</a>] makes some assumptions to approximate the evolution of a population in a continuous space. We refer to the <a href="../overview/#Theory-overview">Theory overview</a> for an introduction to the underlying theory. In any case, we advise researchers to simulate synthetic data that resembles the empirical data according to their expertise. This is a crucial step to determine the expected performance of the method and to guide different steps of the pre-processing strategy (such as which software to use to detect identity-by-descent blocks or how to bin the observed data).</p><p>For this purpose, we provide a <code>SLiM</code> [<a href="../references/#haller_tree-sequence_2019">2</a>] model to simulate an individual-based population in a continuous space as well as two scripts that fit the model with either error-free identity-by-descent blocks or blocks detected using state-of-the-art software and compare it with the ground-truth parameters. Such models can be found at <a href="https://github.com/currocam/IdentityByDescentDispersal.jl/tree/main/simulations">simulations directory</a> and might be adapted to your specific needs.</p><h2 id="Processing-pipeline"><a class="docs-heading-anchor" href="#Processing-pipeline">Processing pipeline</a><a id="Processing-pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Processing-pipeline" title="Permalink"></a></h2><p>Inferring the effective density and dispersal rate from empirical datasets requires running an identity-by-descent detection software across different phased VCF files, post-processing them, and aggregating them appropriately. This procedure is error-prone and time-consuming.</p><p>To facilitate the analysis, we provide a <a href="https://github.com/currocam/IdentityByDescentDispersal.jl/blob/main/Snakefile">Snakemake pipeline</a> that can be used to perform a complete analysis, from detecting IBD blocks using <a href="https://github.com/browning-lab/hap-ibd">HapIBD</a>, post-processing them with <a href="https://faculty.washington.edu/browning/refined-ibd.html">Refined IBD</a>, producing a CSV directly compatible with this package, and, optionally, finding a preliminary maximum likelihood estimate of the effective density and effective dispersal rate. <a href="https://snakemake.readthedocs.io/">Snakemake</a> is a popular tool in bioinformatics and it allows easy parallelization across multiple cores or jobs when submitting to a cluster via SLURM, as well as automatically managing dependencies via Conda or Apptainer containers. Most of the time, running such a pipeline would require a single-command such as:</p><pre><code class="language-bash hljs">snakemake -s Snakefile --configfile config.yaml --cores 8 --sdm conda</code></pre><p>The pipeline is configured via a configuration YAML file. An example of such a configuration file can be found <a href="https://github.com/currocam/IdentityByDescentDispersal.jl/blob/main/.test-workflow/config.yaml">here</a>. You can also find a toy compatible dataset at the <a href="https://github.com/currocam/IdentityByDescentDispersal.jl/tree/main/.test-workflow">.test-workflow subdirectory</a> We refer to the <a href="https://snakemake.readthedocs.io/">extensive documentation of Snakemake</a> for more information.</p><h2 id="Model-inference"><a class="docs-heading-anchor" href="#Model-inference">Model inference</a><a id="Model-inference-1"></a><a class="docs-heading-anchor-permalink" href="#Model-inference" title="Permalink"></a></h2><p>Next, we exemplify the common steps of an analysis using <code>IdentityByDescentDispersal</code>. First, we load a synthetic dataset for which we know the ground truth. This is the dataset we simulated when showcasing how to <a href="https://github.com/currocam/IdentityByDescentDispersal.jl/blob/main/simulations/simulate_constant_density_ground_truth.md">simulate synthetic datasets using SLiM</a>.</p><pre><code class="language-julia hljs">using JLD2, DataFrames, IdentityByDescentDispersal, Turing, Random
Random.seed!(1234)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Random.TaskLocalRNG()</code></pre><p>Load the synthetic dataset from the package&#39;s docs/data directory</p><pre><code class="language-julia hljs">data = load(
    joinpath(pkgdir(IdentityByDescentDispersal), &quot;docs&quot;, &quot;data&quot;, &quot;constant_density.jld2&quot;),
)
ground_truth = (data[&quot;local_density&quot;], data[&quot;dispersal_rate&quot;])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(200, 0.10024968827881711)</code></pre><p>The <code>IdentityByDescentDispersal</code> is designed to be compatible with existing statistical software. Here, we decide to Use the <code>Turing</code> package, which is the most popular Bayesian modelling framework in Julia. Let&#39;s consider the following model:</p><pre><code class="language-julia hljs">@model function constant_density(df, contig_lengths)
    De ~ Truncated(Normal(1000, 100), 0, Inf)
    σ ~ Truncated(Normal(1, 0.1), 0, Inf)
    Turing.@addlogprob! composite_loglikelihood_constant_density(
        De,
        σ,
        df,
        contig_lengths,
        verbose = false,
    )
end
m = constant_density(data[&quot;df&quot;], data[&quot;contig_lengths&quot;])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DynamicPPL.Model{typeof(Main.constant_density), (:df, :contig_lengths), (), (), Tuple{DataFrames.DataFrame, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext, false}(Main.constant_density, (df = 2080×6 DataFrame
  Row │ DISTANCE_INDEX  IBD_LEFT  IBD_RIGHT  NR_PAIRS  COUNT  DISTANCE 
      │ Float64         Float64   Float64    Int64     Int64  Float64  
──────┼────────────────────────────────────────────────────────────────
    1 │           0.25     0.04       0.041       655     66  0.275209
    2 │           0.25     0.041      0.042       655     33  0.275209
    3 │           0.25     0.042      0.043       655     48  0.275209
    4 │           0.25     0.043      0.044       655     59  0.275209
    5 │           0.25     0.044      0.045       655     42  0.275209
    6 │           0.25     0.045      0.046       655     21  0.275209
    7 │           0.25     0.046      0.047       655     29  0.275209
    8 │           0.25     0.047      0.048       655     36  0.275209
  ⋮   │       ⋮            ⋮          ⋮         ⋮        ⋮       ⋮
 2074 │           0.6      0.193      0.194         5      0  0.619258
 2075 │           0.6      0.194      0.195         5      0  0.619258
 2076 │           0.6      0.195      0.196         5      0  0.619258
 2077 │           0.6      0.196      0.197         5      0  0.619258
 2078 │           0.6      0.197      0.198         5      0  0.619258
 2079 │           0.6      0.198      0.199         5      0  0.619258
 2080 │           0.6      0.199      0.2           5      0  0.619258
                                                      2065 rows omitted, contig_lengths = [1.0]), NamedTuple(), DynamicPPL.DefaultContext())</code></pre><p>The <code>IdentityByDescentDispersal</code> is compatible with automatic differentiation. Therefore, we can use standard Hamiltonian Monte Carlo algorithms such as <code>NUTS()</code> to estimate the posterior distribution.</p><pre><code class="language-julia hljs">chains = sample(m, NUTS(), MCMCThreads(), 500, 4; progress = false);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Found initial step size
└   ϵ = 0.0125
┌ Info: Found initial step size
└   ϵ = 0.003125
┌ Info: Found initial step size
└   ϵ = 0.003125
┌ Info: Found initial step size
└   ϵ = 0.0015625</code></pre><p>When fitting models with power-densities (i.e. using <code>composite_loglikelihood_power_density</code>), be aware that the <span>$\beta$</span> parameter controls the mean-square diﬀerentiability of the composite likelihood (through modified second-kind Bessel function). If you run into issues, we suggest that:</p><ul><li>reparametrize the model (perhaps using a custom function via the <code>composite_loglikelihood_custom</code> interface).</li><li>tighten the priors to constrain the space of parameters to a region where gradients are defined.</li><li>use gradient-free inference methods such as <code>Nelder-Mead</code> when computing maximum likelihood estimates or <code>Metropolis-Hastings</code> when doing Bayesian inference.</li></ul><h2 id="Model-diagnosis"><a class="docs-heading-anchor" href="#Model-diagnosis">Model diagnosis</a><a id="Model-diagnosis-1"></a><a class="docs-heading-anchor-permalink" href="#Model-diagnosis" title="Permalink"></a></h2><p>Diagnosing the posterior samples obtained via Markov Chain Monte Carlo is a crucial step in any Bayesian inference. We refer to existing resources such as this lecture on <a href="https://myweb.uiowa.edu/pbreheny/uk/teaching/701/notes/3-5.pdf">Bayesian modelling in Biostatistics.</a> Most popular approaches involve calculating quantities such as the effective number of samples (ESS) and <span>$\hat {R}$</span>, which can be computed directly from <code>Turing</code> output.</p><p>As a rule of thumb, we aim to run the chain long enough to obtain an ESS greater than 100.</p><pre><code class="language-julia hljs">ess(chains) |&gt; DataFrame</code></pre><div><div style = "float: left;"><span>2×3 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">parameters</th><th style = "text-align: left;">ess</th><th style = "text-align: left;">ess_per_sec</th></tr><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">De</td><td style = "text-align: right;">459.605</td><td style = "text-align: right;">1.57679</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">σ</td><td style = "text-align: right;">462.274</td><td style = "text-align: right;">1.58595</td></tr></tbody></table></div><p>A <span>$\hat {R}$</span> greater than 1.05 indicates the chains have not mixed well.</p><pre><code class="language-julia hljs">rhat(chains) |&gt; DataFrame</code></pre><div><div style = "float: left;"><span>2×2 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">parameters</th><th style = "text-align: left;">rhat</th></tr><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">De</td><td style = "text-align: right;">1.00523</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">σ</td><td style = "text-align: right;">1.00596</td></tr></tbody></table></div><p>Convergence issues can also be inspected through a <code>traceplot</code>:</p><pre><code class="language-julia hljs">using Plots, StatsPlots
traceplot(chains)</code></pre><img src="6fba2bc7.svg" alt="Example block output"/><h2 id="Visualizing-the-posterior"><a class="docs-heading-anchor" href="#Visualizing-the-posterior">Visualizing the posterior</a><a id="Visualizing-the-posterior-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-the-posterior" title="Permalink"></a></h2><p>After finishing the sampling process and assessing convergence, we can visualize the estimated posterior distribution of the parameters and compare it with the prior distribution and the ground-truth:</p><pre><code class="language-julia hljs">using Distributions
p1 = plot(
    Truncated(Normal(1000, 100), 0, Inf),
    label = &quot;Prior&quot;,
    xlab = &quot;Effective population density&quot;,
    ylab = &quot;Density&quot;,
)
density!(p1, chains[:De][:], label = &quot;Posterior&quot;)
vline!(p1, [ground_truth[1]], label = &quot;Ground-truth&quot;)

p2 = plot(
    Truncated(Normal(1, 0.1), 0, Inf),
    label = &quot;Prior&quot;,
    xlab = &quot;Effective dispersal rate&quot;,
    ylab = &quot;Density&quot;,
)
density!(p2, chains[:σ][:], label = &quot;Posterior&quot;)
vline!(p2, [ground_truth[2]], label = &quot;Ground-truth&quot;)
plot(p1, p2, layout = (2, 1), size = (600, 800))</code></pre><img src="ae32bebe.svg" alt="Example block output"/><p>Notice that, although the inference is accurate, we do not expect the posterior estimates to have nominal coverage (e.g., that a 90% credibility interval contains the true parameter 90% of the time). This is because we are assuming every pairwise observation is independent when constructing the composite likelihood and therefore we are overconfident in our estimations. In their publication, [<a href="../references/#ringbauer_inferring_2017">1</a>] computed a bootstrapping confidence interval of the maximum-likelihood estimate but still do not achieve nominal coverage.</p><p>A bootstrapping confidence interval can be easily computed with the <code>maximum_likelihood</code> function and taking samples with replacement of the rows of the <code>DataFrame</code>. Notice, however, that other resampling schemes are possible. We advise you to experiment with different approaches and evaluate the performance with simulated datasets.</p><pre><code class="language-julia hljs">nboots = 100
boots = zeros(2, nboots)
df = data[&quot;df&quot;]
for i = 1:nboots
    df_resampled = df[sample(1:nrow(df), nrow(df), replace = true), :]
    mle = maximum_likelihood(constant_density(df_resampled, data[&quot;contig_lengths&quot;]))
    boots[:, i] = mle.values
end
conf_De = quantile(boots[1, :], [0.025, 0.975])
conf_σ = quantile(boots[2, :], [0.025, 0.975])
DataFrame(
    parameter = [&quot;De&quot;, &quot;σ&quot;],
    confidence_interval95 = [conf_De, conf_σ],
    ground_truth = [ground_truth[1], ground_truth[2]],
)</code></pre><div><div style = "float: left;"><span>2×3 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">parameter</th><th style = "text-align: left;">confidence_interval95</th><th style = "text-align: left;">ground_truth</th></tr><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;"></th><th title = "String" style = "text-align: left;">String</th><th title = "Vector{Float64}" style = "text-align: left;">Array…</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">De</td><td style = "text-align: left;">[159.21, 234.436]</td><td style = "text-align: right;">200.0</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">σ</td><td style = "text-align: left;">[0.0925056, 0.11876]</td><td style = "text-align: right;">0.10025</td></tr></tbody></table></div><h2 id="Interpreting-the-output"><a class="docs-heading-anchor" href="#Interpreting-the-output">Interpreting the output</a><a id="Interpreting-the-output-1"></a><a class="docs-heading-anchor-permalink" href="#Interpreting-the-output" title="Permalink"></a></h2><p>Finally, we provide some references on how to interpret the results and relate them to the biological context.</p><h3 id="Effective-population-density"><a class="docs-heading-anchor" href="#Effective-population-density">Effective population density</a><a id="Effective-population-density-1"></a><a class="docs-heading-anchor-permalink" href="#Effective-population-density" title="Permalink"></a></h3><p>The effective population density (De) is simply the inverse of the coalescent rate of lineages that become very close to each other. It is equivalent to the effective population size of every deme in a stepping stone model where demes are separated by one distance unit.</p><p>The estimate is most informative of recent demographic events as it is calculated from long identity-by-descent blocks that typically arise recently. We can get an idea of the temporal time-scale by looking at the theoretical predictions under the estimated demographic model.</p><p>In a Bayesian setting, this sort of information is known as a posterior predictive distribution. Next, we provide a snippet of code that demonstrates how to do this provided a MCMC sample.</p><pre><code class="language-julia hljs">let
    grid_times = 1:100
    L = 0.04 # Smallest IBD block considered
    grid_r = [0.1, 0.5, 1.0] # Geographic distances
    colors = [:blue, :red, :green] # Define colors for each r
    De(t, params) = params[1] # Custom De(t) parametrization
    p1 = plot(xlabel = &quot;Time (generations ago)&quot;, ylabel = &quot;Density shared IBD blocks&quot;)
    posterior = sample(chains, 100)
    for (i, r) in enumerate(grid_r)
        first_line = true
        for (D, sigma) in zip(posterior[:De], posterior[:σ])
            params = [D]
            dens = age_density_ibd_blocks_custom(
                grid_times,
                r,
                De,
                params,
                sigma,
                L,
                data[&quot;contig_lengths&quot;],
            )
            plot!(
                p1,
                grid_times,
                dens,
                label = first_line ? &quot;Distance=$r&quot; : &quot;&quot;,
                color = colors[i],
                alpha = 0.1,
            )
            first_line = false
        end
    end
    p1
end</code></pre><img src="5e25c041.svg" alt="Example block output"/><p>An equivalent plot can be done in a likelihood (frequentist) setting. For example, by calculating the densities for each bootstrap replicate.</p><pre><code class="language-julia hljs">let
    grid_times = 1:100
    L = 0.04 # Smallest IBD block considered
    grid_r = [0.1, 0.5, 1.0] # Geographic distances
    colors = [:blue, :red, :green] # Define colors for each r
    De(t, params) = params[1] # Custom De(t) parametrization
    p1 = plot(xlabel = &quot;Time (generations ago)&quot;, ylabel = &quot;Density shared IBD blocks&quot;)
    for (i, r) in enumerate(grid_r)
        first_line = true
        for j = 1:nboots
            D, sigma = boots[:, j]
            params = [D]
            dens = age_density_ibd_blocks_custom(
                grid_times,
                r,
                De,
                params,
                sigma,
                L,
                data[&quot;contig_lengths&quot;],
            )
            plot!(
                p1,
                grid_times,
                dens,
                label = first_line ? &quot;Distance=$r&quot; : &quot;&quot;,
                color = colors[i],
                alpha = 0.1,
            )
            first_line = false
        end
    end
    p1
end</code></pre><img src="b9e55ca8.svg" alt="Example block output"/><p>We expect to observe a decay in the density of expected shared IBD-blocks with time. The previous plot can be used to determine some time interval <span>$(1, t)$</span> from which we expect most of the signal to have arisen. This recipe is useful for identifying the time-span of the estimated demography and can be applied to other demographic models as well.</p><h3 id="Effective-dispersal-rate"><a class="docs-heading-anchor" href="#Effective-dispersal-rate">Effective dispersal rate</a><a id="Effective-dispersal-rate-1"></a><a class="docs-heading-anchor-permalink" href="#Effective-dispersal-rate" title="Permalink"></a></h3><p>Perhaps unintuitively, the mean per-generation dispersal distance when we average with respect to both parents is not necessarily equivalent to the mean per-generation dispersal distance when we average across single generations. From population genetic data, we can estimate the latter ( refer to the <a href="../overview/#Theory-overview">Theory overview</a> section for more details). Therefore, interpreting the estimated effective dispersal rate in the context of the ecology of one population has to be done carefully.</p><p>For example, consider a population with two separate sexes for which there are differences in the process of dispersal. Such differences arise naturally when considering the effect of mating systems on dispersal patterns. For simplicity, let&#39;s consider a 1-dimensional space where individuals can only move left or right as shown in the figure below.</p><p><img src="../dispersal.png" alt="Illustration of dispersal in a 1-dimensional space with separate sexes"/></p><p>Let&#39;s assume the displacement between the mother and the offspring, <span>$d_{\text{mother-child}}$</span>, is distributed according to a normal distribution with a mean of zero and a variance of <span>$\sigma_D^2$</span> and the displacement between the father and the mother, <span>$d_{\text{mother-father}}$</span>, is also distributed according to a normal distribution with a mean of zero and a variance of <span>$\sigma_M^2$</span>. Because the mating process (that determines the displacement from the mother to the father) is independent from the specific dispersal process of the offspring (that determines the displacement from the mother to the offspring), then the displacement between the father and the offspring is distributed according to a normal distribution with a mean of zero and a variance of <span>$\sigma_D^2 + \sigma_M^2$</span>.</p><p>As mentioned earlier, what we can estimate is the mean per-generation dispersal of the &quot;lineages&quot;. Because the lineage is either inherited from the mother or the father, the displacement is distributed as a mixture of two normal distributions. If sex ratio is 0.5, then the displacement is distributed as a mixture of two normal distributions with weights <span>$w = [0.5, 0.5]$</span>. This distribution has a mean of zero and a variance of <span>$\sigma_D^2 + 0.5\sigma_M^2$</span> but it is <em>not</em> normally distributed. Therefore, and under these assumptions, what we can estimate from genetic data is actually <span>$\sigma = \sqrt{0.5\sigma_D^2 + 0.5(\sigma_D^2+\sigma_M^2)} = \sqrt{\sigma_D^2 + 0.5\sigma_M^2)}$</span> and it is not possible to separate the effects of <span>$\sigma_D$</span> and <span>$\sigma_M$</span> without additional information. If a priori information is available, it is possible to obtain estimates of both <span>$\sigma_D$</span> and <span>$\sigma_M$</span> that are consistent with the observed data. However, this requires additional consideration as the posterior distribution will be multimodal.</p><pre><code class="language-julia hljs">@model function constant_density2(df, contig_lengths)
    De ~ Truncated(Normal(1000, 100), 0, Inf)
    σ_D ~ Truncated(Normal(1, 0.1), 0, Inf)
    σ_M ~ Truncated(Normal(0.1, 0.01), 0, Inf)
    σ := sqrt(σ_D^2 + 0.5 * σ_M^2)
    Turing.@addlogprob! composite_loglikelihood_constant_density(De, σ, df, contig_lengths)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">constant_density2 (generic function with 2 methods)</code></pre><p>As mentioned earlier, the per-generation distance averaging across lineages is not necessarily equal to the mean per-generation distance when we average with respect to both mother and father. Notice that the average displacement is defined as <span>$\hat d = 0.5 d_{\text{mother-child}} + 0.5 (d_{\text{mother-child} - d_{\text{mother-father}}})$</span> which is distributed as a normal distribution with mean zero and variance <span>$\sqrt{\sigma_{D}^{2} + 0.25 \sigma_{M}^{2}}$</span>.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Basic usage</a><a class="docs-footer-nextpage" href="../95-reference/">API reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 16 February 2026 14:08">Monday 16 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
